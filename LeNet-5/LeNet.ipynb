{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cPZzeQdLhDn",
        "outputId": "d80423a2-fe26-4fbb-89f9-206329de0f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ],
      "source": [
        "%pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rv6DWKpvzVU"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from random import choices\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import optuna\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "RkJ4w6hN0FK3"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "seed = 42\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFxVFk-wzNYc"
      },
      "outputs": [],
      "source": [
        "torch.random.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "EeK3H05MwGFr"
      },
      "outputs": [],
      "source": [
        "training_dataset = torchvision.datasets.MNIST(root=\"./\", download=True, train=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root=\"./\", download=True, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "SkffnxeHIlCU"
      },
      "outputs": [],
      "source": [
        "transformation = torchvision.transforms.Compose([torchvision.transforms.ToPILImage(), torchvision.transforms.Pad(padding=2, fill=0), torchvision.transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "pZjcVwye-GFe"
      },
      "outputs": [],
      "source": [
        "training_images = []\n",
        "test_images = []\n",
        "for img in training_dataset.data:\n",
        "  training_images.append(transformation(img).apply_(lambda el: -0.1 if el == 0 else 1.175))\n",
        "\n",
        "for img in test_dataset.data:\n",
        "  test_images.append(transformation(img).apply_(lambda el: -0.1 if el == 0 else 1.175))\n",
        "\n",
        "X_train = torch.stack(training_images)\n",
        "X_test = torch.stack(test_images)\n",
        "train_labels = training_dataset.targets\n",
        "test_labels = test_dataset.targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "LKvX4KL4lHbJ"
      },
      "outputs": [],
      "source": [
        "y_train = torch.Tensor([[1 if i == el else 0 for i in range(10)] for el in train_labels])\n",
        "y_test = torch.Tensor([[1 if i == el else 0 for i in range(10)] for el in test_labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJbj5yvyL14z"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "6Fe6BypxODDe"
      },
      "outputs": [],
      "source": [
        "class LeNet(nn.Module):\n",
        "\n",
        "  def subsample1(self, batch):\n",
        "\n",
        "\n",
        "    return nn.functional.sigmoid(nn.functional.conv2d(batch, torch.stack([torch.full(size=(1, 2, 2), fill_value = 1, device=device)*self.weight1[i] for i in range(6)]), stride=2, bias=self.bias1, groups=6))\n",
        "\n",
        "  def subsample2(self, batch):\n",
        "\n",
        "    return nn.functional.sigmoid(nn.functional.conv2d(batch, torch.stack([torch.full(size=(1, 2, 2), fill_value = 1, device=device)*self.weight2[i] for i in range(16)]), stride=2, bias=self.bias2, groups=16))\n",
        "\n",
        "  def squashed_sigmoid(self, x, A = 1.7159, S = 2/3):\n",
        "    return A * torch.nn.functional.tanh(S * x)\n",
        "\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    rbf_weights = choices([-1, 1], weights = [0.5, 0.5], k=840)\n",
        "    self.rbf_weights = torch.Tensor(rbf_weights).reshape((10, 84)).to(device)\n",
        "\n",
        "    self.weight1 = nn.Parameter(torch.ones(6)).to(device)\n",
        "    self.bias1 = nn.Parameter(torch.ones(6)).to(device)\n",
        "    self.weight2 = nn.Parameter(torch.ones(16)).to(device)\n",
        "    self.bias2 = nn.Parameter(torch.ones(16)).to(device)\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "    self.c3conv0 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=5)\n",
        "    self.c3conv1 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=5)\n",
        "    self.c3conv2 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=5)\n",
        "    self.c3conv3 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=5)\n",
        "    self.c3conv4 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=5)\n",
        "    self.c3conv5 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=5)\n",
        "    self.c3conv6 = nn.Conv2d(in_channels=4, out_channels=1, kernel_size=5)\n",
        "    self.c3conv7 = nn.Conv2d(in_channels=4, out_channels=1, kernel_size=5)\n",
        "    self.c3conv8 = nn.Conv2d(in_channels=4, out_channels=1, kernel_size=5)\n",
        "    self.c3conv9 = nn.Conv2d(in_channels=4, out_channels=1, kernel_size=5)\n",
        "    self.c3conv10 = nn.Conv2d(in_channels=4, out_channels=1, kernel_size=5)\n",
        "    self.c3conv11 = nn.Conv2d(in_channels=4, out_channels=1, kernel_size=5)\n",
        "    self.c3conv12 = nn.Conv2d(in_channels=4, out_channels=1, kernel_size=5)\n",
        "    self.c3conv13 = nn.Conv2d(in_channels=4, out_channels=1, kernel_size=5)\n",
        "    self.c3conv14 = nn.Conv2d(in_channels=4, out_channels=1, kernel_size=5)\n",
        "    self.c3conv15 = nn.Conv2d(in_channels=6, out_channels=1, kernel_size=5)\n",
        "    self.conv4 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5)\n",
        "    self.fc1 = nn.Linear(in_features = 120, out_features = 84)\n",
        "    self.fc2 = nn.Linear(in_features = 84, out_features = 10)\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.subsample1(x)\n",
        "\n",
        "    x0 = x[:, [0, 1, 2]]\n",
        "    x1 = x[:, [1, 2, 3]]\n",
        "    x2 = x[:, [2, 3, 4]]\n",
        "    x3 = x[:, [3, 4, 5]]\n",
        "    x4 = x[:, [0, 4, 5]]\n",
        "    x5 = x[:, [0, 1, 5]]\n",
        "    x6 = x[:, [0, 1, 2, 3]]\n",
        "    x7 = x[:, [1, 2, 3, 4]]\n",
        "    x8 = x[:, [2, 3, 4, 5]]\n",
        "    x9 = x[:, [0, 3, 4, 5]]\n",
        "    x10 = x[:, [0, 1, 4, 5]]\n",
        "    x11 = x[:, [0, 1, 2, 5]]\n",
        "    x12 = x[:, [0, 1, 3, 4]]\n",
        "    x13 = x[:, [1, 2, 4, 5]]\n",
        "    x14 = x[:, [0, 2, 3, 5]]\n",
        "    x15 = x[:, :]\n",
        "    x0 = self.c3conv0(x0.to(device))\n",
        "    x1 = self.c3conv1(x1.to(device))\n",
        "    x2 = self.c3conv2(x2.to(device))\n",
        "    x3 = self.c3conv3(x3.to(device))\n",
        "    x4 = self.c3conv4(x4.to(device))\n",
        "    x5 = self.c3conv5(x5.to(device))\n",
        "    x6 = self.c3conv6(x6.to(device))\n",
        "    x7 = self.c3conv7(x7.to(device))\n",
        "    x8 = self.c3conv8(x8.to(device))\n",
        "    x9 = self.c3conv9(x9.to(device))\n",
        "    x10 = self.c3conv10(x10.to(device))\n",
        "    x11 = self.c3conv11(x11.to(device))\n",
        "    x12 = self.c3conv12(x12.to(device))\n",
        "    x13 = self.c3conv13(x13.to(device))\n",
        "    x14 = self.c3conv14(x14.to(device))\n",
        "    x15 = self.c3conv15(x15.to(device))\n",
        "    x = torch.stack([x0, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15], dim=1).reshape((x.shape[0], 16, 10, 10))\n",
        "    x = self.subsample2(x)\n",
        "    x = self.conv4(x.to(device))\n",
        "    x = torch.flatten(x, 1, -1)\n",
        "    x = self.fc1(x)\n",
        "    x = self.squashed_sigmoid(x)\n",
        "    x = self.fc2(x)\n",
        "    return nn.functional.softmax(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ehg8tOsHzZ8x"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    torch.random.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [256, 512, 1024, 2048, 4096])\n",
        "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.00001, 0.1)\n",
        "    optim = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"AdamW\", \"RAdam\"])\n",
        "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-10, 1e-3)\n",
        "\n",
        "    model = LeNet().to(device)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    train_batches = DataLoader([*zip(X_train, y_train)], batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "    if optim == \"Adam\":\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    elif optim == \"AdamW\":\n",
        "      optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    else:\n",
        "      optimizer = torch.optim.RAdam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    for i in range(10):\n",
        "      model.train()\n",
        "      for batch in train_batches:\n",
        "        optimizer.zero_grad()\n",
        "        features, target = batch[:-1], batch[-1]\n",
        "        features = features[0].to(device)\n",
        "        target = target.to(device)\n",
        "        outputs = model(features)\n",
        "        perte = loss_fn(outputs, target)\n",
        "        perte.backward()\n",
        "        optim.step()\n",
        "    model.eval()\n",
        "    return loss_fn(model(X_val.to(device)), y_val.to(device)).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX9Oc59-ntmZ",
        "outputId": "eb77afd0-5da8-44d3-f029-adb0cd4936c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97.22000122070312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-132-1eaf6305bc48>:94: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return nn.functional.softmax(x)\n"
          ]
        }
      ],
      "source": [
        "sampler = optuna.samplers.TPESampler(seed=seed)\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
        "study.optimize(objective, n_trials = 20)\n",
        "trial = study.best_trial\n",
        "print(trial.params)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
