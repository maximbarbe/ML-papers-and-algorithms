{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31011,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from random import choices, sample\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings"
      ],
      "metadata": {
        "id": "82qODlhuKAwo",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-04T17:20:22.275781Z",
          "iopub.execute_input": "2025-05-04T17:20:22.276413Z",
          "iopub.status.idle": "2025-05-04T17:20:31.181650Z",
          "shell.execute_reply.started": "2025-05-04T17:20:22.276387Z",
          "shell.execute_reply": "2025-05-04T17:20:31.180853Z"
        }
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "seed = 42\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "eWu681IEKPOL",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-04T17:20:31.182923Z",
          "iopub.execute_input": "2025-05-04T17:20:31.183304Z",
          "iopub.status.idle": "2025-05-04T17:20:31.270410Z",
          "shell.execute_reply.started": "2025-05-04T17:20:31.183278Z",
          "shell.execute_reply": "2025-05-04T17:20:31.269695Z"
        }
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "id": "rQenoHs1KQK1",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-04T17:20:31.271379Z",
          "iopub.execute_input": "2025-05-04T17:20:31.271789Z",
          "iopub.status.idle": "2025-05-04T17:20:31.294944Z",
          "shell.execute_reply.started": "2025-05-04T17:20:31.271763Z",
          "shell.execute_reply": "2025-05-04T17:20:31.294251Z"
        }
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "mock_images = torch.randint(0, 256, (1, 1, 572, 572)).float().to(device)"
      ],
      "metadata": {
        "id": "T0qlhj6pKSQs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-04T17:21:28.893002Z",
          "iopub.execute_input": "2025-05-04T17:21:28.893520Z",
          "iopub.status.idle": "2025-05-04T17:21:28.902622Z",
          "shell.execute_reply.started": "2025-05-04T17:21:28.893496Z",
          "shell.execute_reply": "2025-05-04T17:21:28.901758Z"
        }
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3)\n",
        "    self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3)\n",
        "    self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3)\n",
        "    self.conv7 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3)\n",
        "    self.conv8 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3)\n",
        "    self.conv9 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3)\n",
        "    self.conv10 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3)\n",
        "    self.conv11 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=2, stride=2)\n",
        "    self.conv12 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3)\n",
        "    self.conv13 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3)\n",
        "    self.conv14 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2)\n",
        "    self.conv15 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3)\n",
        "    self.conv16 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3)\n",
        "    self.conv17 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=2, stride=2)\n",
        "    self.conv18 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3)\n",
        "    self.conv19 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3)\n",
        "    self.conv20 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2)\n",
        "    self.conv21 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3)\n",
        "    self.conv22 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
        "    self.conv23 = nn.Conv2d(in_channels=64, out_channels=2, kernel_size=1)\n",
        "\n",
        "    self.crop1 = torchvision.transforms.CenterCrop((392, 392))\n",
        "    self.crop2 = torchvision.transforms.CenterCrop((200, 200))\n",
        "    self.crop3 = torchvision.transforms.CenterCrop((104, 104))\n",
        "    self.crop4 = torchvision.transforms.CenterCrop((56, 56))\n",
        "\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.conv1(x))\n",
        "    x = self.relu(self.conv2(x))\n",
        "    x1 = self.crop1(x.clone().detach())\n",
        "    x = self.maxpool(x)\n",
        "    x = self.relu(self.conv3(x))\n",
        "    x = self.relu(self.conv4(x))\n",
        "    x2 = self.crop2(x.clone().detach())\n",
        "    x = self.maxpool(x)\n",
        "    x = self.relu(self.conv5(x))\n",
        "    x = self.relu(self.conv6(x))\n",
        "    x3 = self.crop3(x.clone().detach())\n",
        "    x = self.maxpool(x)\n",
        "    x = self.relu(self.conv7(x))\n",
        "    x = self.relu(self.conv8(x))\n",
        "    x4 = self.crop4(x.clone().detach())\n",
        "    x = self.maxpool(x)\n",
        "    x = self.relu(self.conv9(x))\n",
        "    x = self.relu(self.conv10(x))\n",
        "    x = self.conv11(x)\n",
        "    x = torch.cat((x4, x), dim=1)\n",
        "    x = self.relu(self.conv12(x))\n",
        "    x = self.relu(self.conv13(x))\n",
        "    x = self.conv14(x)\n",
        "    x = torch.cat((x3, x), dim=1)\n",
        "    x = self.relu(self.conv15(x))\n",
        "    x = self.relu(self.conv16(x))\n",
        "    x = self.conv17(x)\n",
        "    x = torch.cat((x2, x), dim=1)\n",
        "    x = self.relu(self.conv18(x))\n",
        "    x = self.relu(self.conv19(x))\n",
        "    x = self.conv20(x)\n",
        "    x = torch.cat((x1, x), dim=1)\n",
        "    x = self.relu(self.conv21(x))\n",
        "    x = self.relu(self.conv22(x))\n",
        "    x = self.conv23(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "8rn0FyyFKX7l",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-04T17:23:58.955858Z",
          "iopub.execute_input": "2025-05-04T17:23:58.956117Z",
          "iopub.status.idle": "2025-05-04T17:23:58.968829Z",
          "shell.execute_reply.started": "2025-05-04T17:23:58.956098Z",
          "shell.execute_reply": "2025-05-04T17:23:58.968114Z"
        }
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet().to(device)\n",
        "model(mock_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZpmvITyLdw6",
        "outputId": "64251534-d499-4863-db8a-e31fea4b28e9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-04T17:24:00.491051Z",
          "iopub.execute_input": "2025-05-04T17:24:00.491527Z",
          "iopub.status.idle": "2025-05-04T17:24:00.882745Z",
          "shell.execute_reply.started": "2025-05-04T17:24:00.491504Z",
          "shell.execute_reply": "2025-05-04T17:24:00.882138Z"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.9295, -0.4955, -0.0597,  ..., -0.8960, -1.2050, -0.2833],\n",
              "          [-1.6364, -0.7513, -1.0377,  ..., -0.8439, -0.6263, -0.7552],\n",
              "          [-0.7889, -1.4408, -1.2966,  ..., -0.5833,  0.4957, -0.1332],\n",
              "          ...,\n",
              "          [-0.5248, -1.1461, -0.9973,  ..., -1.0610, -0.5198,  0.3151],\n",
              "          [-0.9917, -0.6281, -0.9026,  ..., -0.4739, -1.1499,  0.7924],\n",
              "          [-0.6772,  0.2353, -0.7214,  ...,  0.2731, -1.5637, -0.1155]],\n",
              "\n",
              "         [[-0.6106, -0.0313, -0.7558,  ...,  0.3762,  0.6754,  1.4451],\n",
              "          [ 0.0461,  1.0008,  0.5537,  ..., -0.1377,  0.7356,  0.2764],\n",
              "          [-0.4387,  0.1490,  0.1790,  ...,  0.7754,  0.3303,  0.2420],\n",
              "          ...,\n",
              "          [-1.0367, -0.9383,  0.0205,  ..., -0.0858,  0.8842,  0.7873],\n",
              "          [ 0.5883,  0.4170,  0.8936,  ...,  0.4267,  0.2625,  0.5653],\n",
              "          [ 0.3385, -0.5467, -0.1472,  ..., -0.2908,  0.0461,  0.8120]]]],\n",
              "       device='cuda:0', grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "execution_count": 6
    }
  ]
}